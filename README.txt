Portal TransparÃªncia RPA

AutomaÃ§Ã£o em Python/Selenium para extraÃ§Ã£o de dados de beneficiÃ¡rios de programas sociais no Portal da TransparÃªncia.

ğŸš€ ExecuÃ§Ã£o rÃ¡pida

python automacao_copia.py --query "TERMO" --out arquivo.json --visible --debug

ParÃ¢metros

ParÃ¢metro

DescriÃ§Ã£o

ValorÂ padrÃ£o

--query

Filtro de busca (Nome, CPF ou NIS)

"" (todos)

--out

Caminho/arquivo JSON de saÃ­da

beneficiarios.json

--visible

Abre o navegador visÃ­vel (desativa headless)

desligado

--debug

Mostra logs detalhados no console

desligado

ğŸ“‘ SumÃ¡rio

ExecuÃ§Ã£o rÃ¡pida

Contexto do teste

ConsideraÃ§Ãµes tÃ©cnicas

AtualizaÃ§Ãµes

Autor

ğŸ’» Como executar

Para a execuÃ§Ã£o bÃ¡sica:

python automacao_copia.py

Para opÃ§Ãµes avanÃ§adas, consulte a seÃ§Ã£o ExecuÃ§Ã£o rÃ¡pida.

ğŸ“ Contexto do teste

Atualmente estou empregado em um trabalho presencial das 08h Ã s 18h e me foi pedido que eu entregasse o teste atÃ© sextaâ€‘feira (09/05/2025).

Como nÃ£o tenho muito tempo livre, optei por fazer o teste em um Ãºnico dia (08/05/2025) e nÃ£o consegui implementar todas as funcionalidades que gostaria, mas fiz o meu melhor para entregar algo funcional e que atenda ao solicitado.

O total de horas dedicadas foi de aproximadamente 6â€¯h.

Pontos observados

O RPA obtÃ©m os dados dos beneficiados por auxÃ­lio de programa social, porÃ©m trÃªs campos no JSON permanecem vazios.

O primeiro item da lista Ã© ignorado, fazendo com que o item da pÃ¡ginaÂ 2 apareÃ§a como o Ãºltimo da lista de dez resultados.

Ainda nÃ£o testei se todas as capturas de tela estÃ£o corretas, nem se deveria capturar a pÃ¡gina inteira ou apenas o screenshot da viewport.

De qualquer maneira, o cÃ³digo estÃ¡ funcional e pode ser melhorado para atender a todos os requisitos solicitados.

Dentro do contexto de trabalho, certamente eu conseguiria implementar todas as funcionalidades solicitadas, mas devido ao tempo reduzido nÃ£o foi possÃ­vel.

âš™ï¸ ConsideraÃ§Ãµes tÃ©cnicas

Estado inicial (08/05/2025)

Capturando beneficiÃ¡rios, porÃ©m com trÃªs campos vazios no JSON.

Ignorando o primeiro item da lista de resultados.

Realizando screenshots, porÃ©m sem validaÃ§Ã£o completa.

CorreÃ§Ãµes aplicadas (09/05/2025)

Tratamento especÃ­fico para cada benefÃ­cio, pois suas colunas diferem.

Descoberto o endpoint da API de parcelas â€“ captura via requisiÃ§Ãµes HTTP substituiu a manipulaÃ§Ã£o de DOM.

Ajustado o parÃ¢metro de paginaÃ§Ã£o (tamanhoPagina=1000) para retornar todas as parcelas em uma Ãºnica chamada.

Implementado fechamento automÃ¡tico do painel de cookies para evitar bloqueio de cliques.

Reconhecida a limitaÃ§Ã£o imposta por CAPTCHA â€“ execuÃ§Ã£o requer intervenÃ§Ã£o humana caso apareÃ§a.

Constatado que, apÃ³s as correÃ§Ãµes, o sistema cumpre 100Â % dos objetivos em ~95Â % das execuÃ§Ãµes.

ğŸ—“ AtualizaÃ§Ãµes

Data

DescriÃ§Ã£o

09/05/2025

CorreÃ§Ãµes gerais: mapeamento de colunas, uso de API JSON, tratamento do cookieâ€‘bar, paginaÃ§Ã£o de 1â€¯000 parcelas.

13/05/2025

InÃ­cio do processo de refatoraÃ§Ã£o e reorganizaÃ§Ã£o do projeto em mÃ³dulos (driver.py, scraper.py, etc.).

ğŸ‘¤ Autor

Henrique Luna

"Com certeza o sistema pode ser melhorado, pois sempre pode ser melhorado, mas atualmente diria que ele cumpre 100Â % dos objetivos em aproximadamente 95Â % dos casos."